{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# English Premier League Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as grid_spec\n",
    "import matplotlib.patches as mpatches\n",
    "import random\n",
    "import warnings\n",
    "import platform\n",
    "import time\n",
    "import re\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV, learning_curve\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import naive_bayes\n",
    "from sklearn import preprocessing\n",
    "\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction/ Motivation\n",
    "Every year in English Premier League (EPL), all clubs are striving to get into the top 4 in the league so that they can participate in the Champions League, which is the biggest competition in Europe. We have some ideas about what a team should do to win a match such as accurate passing, high pressure, more shots on target, etc… As a Data science enthusiast and a huge soccer fan, I was curious to see if I can prove or find out what features are actually important to win a match. This could make a confident statement about what a team has to focus on to be in the top 4. In addition, it could help to predict what teams are highly likely to be in the top 4 using machine learning models.\n",
    "\n",
    "Data was collected from EPL official website by web scraping(https://github.com/hyunilyoo/epl-webscraper), and splited into two groups, which are teams that are and are not in the top 4  as \"Top 4\" and \"Below 4\". Based on Exploratory Data Analysis, there are features that are significantly different between two groups. In contrast, there are features that are similar between two groups but give interesting insights, for example the number of crosses are higher in Top 4 but the cross accuracy is actually lower than Below 4. \n",
    "\n",
    "Based on EDA, there are 10 features, which are ‘Big chance created’, ‘Clearance’, 'Goal conceded per match', 'Goal per match', 'Pass per game', 'Shot on target', 'Won', 'Lost', 'Drawn', and 'Points', have related with getting into the top 4 in the league. \n",
    "\n",
    "To evaluate the features, I make several baseline models with different algorithms and compare them with a model that contains factors that are from EDA and a model with every feature. After the comparison, Random Forest model is the best model among others and achieves 96% in accuracy  and 0.95 in F1 score.\n",
    "\n",
    "More details are provided in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Dataset  \n",
    "**Source:** Data is gathered by web scraping on EPL official website.  \n",
    "**Period:** From 1993 to 2020  \n",
    "**Features:** Total 23 columns and 566 rows  \n",
    "**Characteristics:** Dataset is composed into two tables. One with final results of its season (it’s called “table.csv”) and one with clubs’ statistics (“club_statistics.csv”). “Table.csv” has all data from 1993 to 2020; however, “club_statistics.csv” missing many factors from 1993 to 2006 due to the data gathering method that EPL had applied in matches. More details are in this link: https://www.premierleague.com/stats/clarification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "if platform.system() == 'Windows':\n",
    "    tables = pd.read_csv('tables_crawler/tables_crawler/spiders/tables.csv')\n",
    "    clubstats = pd.read_csv('clubstats_crawler/clubstats_crawler/spiders/clubstats.csv')\n",
    "else:\n",
    "    tables = pd.read_csv('data/tables.csv')\n",
    "    clubstats = pd.read_csv('data/clubstats.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clubstats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Data Preprocessing\n",
    "- Change into proper data types  \n",
    "- Handling NA values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "**\"tables\" is already in proper data types. Also no NA values.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clubstats.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\"clubstats\" has a few features that are incorrectly formatted.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change to proper data types\n",
    "clubstats['cross_accuracy'] = clubstats['cross_accuracy'].map(lambda x: x.rstrip('%')).astype('int')\n",
    "clubstats['pass_accuracy'] = clubstats['pass_accuracy'].map(lambda x: x.rstrip('%')).astype('int')\n",
    "clubstats['shooting_accuracy'] = clubstats['shooting_accuracy'].map(lambda x: x.rstrip('%')).astype('int')\n",
    "clubstats['tackle_success'] = clubstats['tackle_success'].map(lambda x: x.rstrip('%')).astype('int')\n",
    "clubstats['aerial_battles'] = clubstats['aerial_battles'].str.replace(',','').astype('int')\n",
    "clubstats['clearance'] = clubstats['clearance'].str.replace(',','').astype('int')\n",
    "clubstats['cross'] = clubstats['cross'].str.replace(',','').astype('int')\n",
    "\n",
    "# In 'clubstats' AFC Bournemouth is named as it is, but in 'tables' it is named as 'Bournemouth'.\n",
    "# So in order to join the two data frames, the club_name for AFC Bournmouth has to be changed.\n",
    "clubstats['club_name'][53] = 'Bournemouth'\n",
    "clubstats['club_name'][54] = 'Bournemouth'\n",
    "clubstats['club_name'][55] = 'Bournemouth'\n",
    "clubstats['club_name'][56] = 'Bournemouth'\n",
    "clubstats['club_name'][57] = 'Bournemouth'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to join two tables, but there is no column that indicate what season it is on 'tables'.  Data were scraped descending order, which is 2019 to 1992, we just need to add the information on 'tables'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "season_info = clubstats[clubstats['club_name'] == \"Arsenal\"]['season']\n",
    "seasons = []\n",
    "\n",
    "for i in range(len(season_info)):\n",
    "    if i < 25:\n",
    "        seasons.append([season_info[i],] * 20)\n",
    "    else:\n",
    "        seasons.append([season_info[i],] * 22)\n",
    "\n",
    "seasons_flat = [season for sub_season in seasons for season in sub_season]\n",
    "tables['season'] = seasons_flat\n",
    "\n",
    "# Join two data frames\n",
    "data = pd.merge(tables, clubstats, on=['club_name', 'season'])\n",
    "\n",
    "# To get total number of games\n",
    "data['total_games'] = data['won'] + data['drawn'] + data['lost']\n",
    "\n",
    "# Add top4 indicator \n",
    "data['is_top4'] = data['position'].apply(lambda x: 1 if (x <= 4) else 0)\n",
    "\n",
    "# Since I want to predict Top 4 for season 2019/20, I will exclude this season.\n",
    "current_season = data[data['season'] == '2019/20']\n",
    "past_seasons = data[data['season'] != '2019/20'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 .Exploratory Data Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual parameters\n",
    "t4_color = '#3d195b'\n",
    "b4_color = '#c9d6df'\n",
    "b_color = '#f7f7f7'\n",
    "seaborn_color = [b4_color, t4_color]\n",
    "sns.set_palette(sns.color_palette(seaborn_color))\n",
    "t4_legend = mpatches.Patch(color=t4_color, label='Top 4', edgecolor='black')\n",
    "b4_legend = mpatches.Patch(color=b4_color, label='Below 4', edgecolor='black')\n",
    "\n",
    "# Seperate into two groups\n",
    "top4 = past_seasons[past_seasons['is_top4'] == 1]\n",
    "below4 = past_seasons[past_seasons['is_top4'] == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Table features\n",
    "There are eight features in the table dataset. Every feature is analyzed except “position”. In this dataset, we can find out the thresholds that how many wins, loses, draws, points, goals, and goals against a team can have to be in the top 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Wins, Loses, Draws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 1, figsize=(20,10))\n",
    "cols = ['won', 'lost', 'drawn']\n",
    "\n",
    "for i, col in enumerate(cols):\n",
    "    t4_index = top4[col].value_counts().index\n",
    "    t4_values = top4[col].value_counts().values\n",
    "    b4_index = below4[col].value_counts().index\n",
    "    b4_values = below4[col].value_counts().values\n",
    "    \n",
    "    ax.flatten()[i].bar(x=t4_index, height=t4_values/1.08, color=t4_color, edgecolor='black', alpha=1, linewidth=2, label='Top 4')\n",
    "    ax.flatten()[i].bar(x=b4_index, height=b4_values/4.38, color=b4_color, edgecolor='black', alpha=0.8, linewidth=2, label='Below 4')\n",
    "    \n",
    "    ax.flatten()[i].grid(which='major', axis='x', zorder=0, alpha=0.3)\n",
    "    ax.flatten()[i].grid(which='major', axis='y', zorder=0, alpha=0.3)\n",
    "    \n",
    "    ax.flatten()[i].set_xticks(np.arange(0, 38, 1))\n",
    "    ax.flatten()[i].set_xticklabels(ax.flatten()[i].get_xticks(), fontsize=15)\n",
    "    ax.flatten()[i].set_yticklabels(ax.flatten()[i].get_yticks(), fontsize=15)\n",
    "    ax.flatten()[i].set_xlabel('Number of games', fontsize=20)\n",
    "    ax.flatten()[i].set_ylabel('%', fontsize=20)\n",
    "    ax.flatten()[i].set_title(col.upper(), weight='bold', fontsize=20)\n",
    "    ax.flatten()[i].set_facecolor(b_color)\n",
    "    \n",
    "    ax.flatten()[i].spines['top'].set_visible(False)\n",
    "    ax.flatten()[i].spines['right'].set_visible(False)\n",
    "    ax.flatten()[i].spines['bottom'].set_linewidth(4)\n",
    "    ax.flatten()[i].spines['left'].set_linewidth(4)\n",
    "    \n",
    "    if i == 0:\n",
    "        ax.flatten()[i].legend(loc=1, shadow=True, fontsize=12)\n",
    "        \n",
    "    \n",
    "\n",
    "fig.set_facecolor(b_color)\n",
    "fig.set_edgecolor('black')\n",
    "fig.tight_layout(pad=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The figure above is showing distributions of the number of win, lost, and draw. We can see if a team has less than 18 wins or more than 11 losts, a team is highly likely to not be in the Top 4. Interestingly, it seems like number of draws are pretty similar between two groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(30,10))\n",
    "col = 'points'\n",
    "\n",
    "t4_index = top4[col].value_counts().index\n",
    "t4_values = top4[col].value_counts().values\n",
    "b4_index = below4[col].value_counts().index\n",
    "b4_values = below4[col].value_counts().values\n",
    "\n",
    "ax.bar(x=t4_index, height=t4_values/1.08, color=t4_color, edgecolor='black', alpha=1, linewidth=2.5, label='Top 4')\n",
    "ax.bar(x=b4_index, height=b4_values/4.38, color=b4_color, edgecolor='black', alpha=0.8, linewidth=2.5, label='Below 4')\n",
    "\n",
    "ax.grid(which='major', axis='x', zorder=0, alpha=0.3)\n",
    "ax.grid(which='major', axis='y', zorder=0, alpha=0.3)\n",
    "\n",
    "ax.set_xticks(np.arange(0, 110, 5))\n",
    "ax.set_title(col.upper(), weight='bold', fontsize=25)\n",
    "ax.set_ylabel('%', fontsize=20)\n",
    "ax.set_xticklabels(ax.get_xticks(), fontsize=20)\n",
    "ax.set_yticklabels(ax.get_yticks(), fontsize=15)\n",
    "ax.xaxis.set_tick_params(labelsize=14)\n",
    "ax.set_facecolor(b_color)\n",
    "\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['bottom'].set_linewidth(4)\n",
    "ax.spines['left'].set_linewidth(4)\n",
    "\n",
    "ax.legend(loc=1, shadow=True, fontsize=18)\n",
    "\n",
    "fig.set_facecolor(b_color)\n",
    "fig.tight_layout(pad=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For points, when a team gets lower than 60 points, the probability of getting into Top 4 gets significantly low. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Goal, Goal Against"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 1, figsize=(20,10))\n",
    "cols = ['goal', 'goal_against']\n",
    "\n",
    "for i, col in enumerate(cols):\n",
    "    t4_index = top4[col].value_counts().index\n",
    "    t4_values = top4[col].value_counts().values\n",
    "    b4_index = below4[col].value_counts().index\n",
    "    b4_values = below4[col].value_counts().values\n",
    "    \n",
    "    ax.flatten()[i].bar(x=t4_index, height=t4_values/1.08, color=t4_color, edgecolor='black', alpha=1, linewidth=1.5, label='Top 4')\n",
    "    ax.flatten()[i].bar(x=b4_index, height=b4_values/4.38, color=b4_color, edgecolor='black', alpha=0.8, linewidth=1.5, label='Below 4')\n",
    "    \n",
    "    ax.flatten()[i].grid(which='major', axis='x', zorder=0, alpha=0.3)\n",
    "    ax.flatten()[i].grid(which='major', axis='y', zorder=0, alpha=0.3)\n",
    "    \n",
    "    ax.flatten()[i].set_xticks(np.arange(0, 110, 5))\n",
    "    ax.flatten()[i].set_title(col.upper(), weight='bold', fontsize=20)\n",
    "    ax.flatten()[i].set_ylabel('%', fontsize=20)\n",
    "    ax.flatten()[i].set_facecolor(b_color)\n",
    "    \n",
    "    ax.flatten()[i].spines['top'].set_visible(False)\n",
    "    ax.flatten()[i].spines['right'].set_visible(False)\n",
    "    ax.flatten()[i].spines['bottom'].set_linewidth(4)\n",
    "    ax.flatten()[i].spines['left'].set_linewidth(4)\n",
    "    \n",
    "    if i == 0:\n",
    "        ax.flatten()[i].legend(loc=1, shadow=True, fontsize=14)\n",
    "\n",
    "fig.set_facecolor(b_color)\n",
    "fig.set_edgecolor('black')\n",
    "fig.tight_layout(pad=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scoring goals and conceding goals also look like there are difference between the groups. In this case, when a team scores less than 50 goals or concedes more than 43 goals, a team will save a hard time to get into Top 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Table features throughout the Seasons\n",
    "Trend of soccer tactics are changing every year or so. Therefore, comparing the features by each season might give some insights whether distribution of the features got changed overtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasons = np.flip(data['season'].unique())\n",
    "\n",
    "t4_legend = mpatches.Patch(color=t4_color, label='Top 4', edgecolor='black')\n",
    "b4_legend = mpatches.Patch(color=b4_color, label='Below 4', edgecolor='black')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Wins, Loses, Draws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cols = ['won', 'lost', 'drawn']\n",
    "\n",
    "fig, ax = plt.subplots(len(seasons[:-1]), 3, figsize=(15, 15), \n",
    "                       sharex=True, gridspec_kw={'hspace':-0.5}, tight_layout=True)\n",
    "\n",
    "for i, col in enumerate(cols):\n",
    "    for j, season in enumerate(seasons[:-1]):\n",
    "        sns.kdeplot(data=data[data['season'] == season], x=col, hue='is_top4',  alpha=.8, \n",
    "                    edgecolor='black', multiple='stack', legend=False, ax=ax[j, i])\n",
    "        ax[j, i].spines['top'].set_visible(False)\n",
    "        ax[j, i].spines['right'].set_visible(False)\n",
    "        ax[j, i].spines['left'].set_visible(False)\n",
    "        ax[j, i].grid(False)\n",
    "        ax[j, i].get_yaxis().set_visible(False)\n",
    "        ax[j, i].set_facecolor('None')\n",
    "\n",
    "        if j != len(seasons[:-1])-1:\n",
    "            ax[j, i].spines['bottom'].set_linewidth(2)\n",
    "            ax[j, i].set_xticks(np.arange(0, 40, 5))\n",
    "            ax[j, i].get_xaxis().set_visible(False)\n",
    "            ax[j, i].text(-15, 0, season, fontweight='bold', fontsize=12)\n",
    "        else:\n",
    "            ax[j, i].get_xaxis().set_visible(True)\n",
    "            ax[j, i].text(-15, 0, season, fontweight='bold', fontsize=12)\n",
    "            ax[j, i].set_xlabel(col, fontsize=16, fontweight='bold')\n",
    "\n",
    "fig.legend(bbox_to_anchor=(0.9, 0.9), handles=[t4_legend, b4_legend], shadow=True, fontsize=12)\n",
    "fig.text(0.12, 0.9, 'Distributions through 1992 to 2018', fontsize=18, fontweight='bold')     \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The figures above are distribution plots throughout the seasons for the number of win, lost and draw games. \n",
    "\n",
    "Based on the plots, the distributions of won and lost were changed time to time, but it did not consistently change throughout the years. In some seasons, \"Top 4\" teams has a wide distribution of won and lost. That means there is a team that outperformed the others by a lot in those seasons. Therefore, we can say the number of wins and losts did not change much for the past 26 years, and they are constantly far apart from each other. However, if you look at draw games, Top 4 and Below 4 are very close to each other, and sometimes Top 4 has more draw games than Below 4. \n",
    "\n",
    "To sum up, we can conclude that there is no difference in the number of results throughout the years, and the number of  wins and losts are always distinguishable between Top 4 and Below 4, but the number of draw games can be very similar to each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(len(seasons[:-1]), 1, figsize=(10, 10), \n",
    "                       sharex=True, gridspec_kw={'hspace':-0.5}, tight_layout=True)\n",
    "\n",
    "for j, season in enumerate(seasons[:-1]):\n",
    "    sns.kdeplot(data=data[data['season'] == season], x='points', hue='is_top4',  alpha=.8, \n",
    "                edgecolor='black', multiple='stack', legend=False, ax=ax[j])\n",
    "    \n",
    "    ax[j].spines['top'].set_visible(False)\n",
    "    ax[j].spines['right'].set_visible(False)\n",
    "    ax[j].spines['left'].set_visible(False)\n",
    "    ax[j].grid(False)\n",
    "    ax[j].get_yaxis().set_visible(False)\n",
    "    ax[j].set_facecolor('None')\n",
    "    \n",
    "    if j != len(seasons[:-1])-1:\n",
    "        ax[j].spines['bottom'].set_linewidth(2)\n",
    "        ax[j].get_xaxis().set_visible(False)\n",
    "        ax[j].set_xticks(np.arange(0,130,10))\n",
    "        ax[j].text(-30, 0, season, fontweight='bold', fontsize=12)\n",
    "    else:\n",
    "        ax[j].get_xaxis().set_visible(True)\n",
    "        ax[j].set_xticks(np.arange(0,130,10))\n",
    "        ax[j].set_xlabel('points', fontsize=16, fontweight='bold')\n",
    "        ax[j].text(-30, 0, season, fontweight='bold', fontsize=12)\n",
    "\n",
    "fig.legend(bbox_to_anchor=(0.9, 0.9), handles=[t4_legend, b4_legend], shadow=True, fontsize=12)\n",
    "fig.text(0.12, 0.9, 'Distributions through 1992 to 2018', fontsize=18, fontweight='bold')     \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot shows there is no change in points throughout the years in both groups (but we can observe seasons with wide distributions that similar to the previous plot). Based on the observation, a team needs at least 60 points to increase the chance to be in the top 4. Otherwise, the probability of a team getting into the top 4 is very low. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Goals and Goals Against"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['goal', 'goal_against']\n",
    "\n",
    "fig, ax = plt.subplots(len(seasons[:-1]), 2, figsize=(15, 15), \n",
    "                       sharex=True, gridspec_kw={'hspace':-0.5}, tight_layout=True)\n",
    "\n",
    "for i, col in enumerate(cols):\n",
    "    for j, season in enumerate(seasons[:-1]):\n",
    "        sns.kdeplot(data=data[data['season'] == season], x=col, hue='is_top4',  alpha=.8, \n",
    "                    edgecolor='black', multiple='stack', legend=False, ax=ax[j, i])\n",
    "        \n",
    "        ax[j, i].spines['top'].set_visible(False)\n",
    "        ax[j, i].spines['right'].set_visible(False)\n",
    "        ax[j, i].spines['left'].set_visible(False)\n",
    "        ax[j, i].grid(False)\n",
    "        ax[j, i].get_yaxis().set_visible(False)\n",
    "        ax[j, i].set_facecolor('None')\n",
    "\n",
    "        if j != len(seasons[:-1])-1:\n",
    "            ax[j, i].spines['bottom'].set_linewidth(2)\n",
    "            ax[j, i].get_xaxis().set_visible(False)\n",
    "            ax[j, i].text(-18, 0, season, fontweight='bold', fontsize=12)\n",
    "        else:\n",
    "            ax[j, i].get_xaxis().set_visible(True)\n",
    "            ax[j, i].text(-18, 0, season, fontweight='bold', fontsize=12)\n",
    "            ax[j, i].set_xlabel(col, fontsize=16, fontweight='bold')\n",
    "            ax[j, i].set_xticks(np.arange(0,130,10))\n",
    "\n",
    "fig.legend(bbox_to_anchor=(0.9, 0.9), handles=[t4_legend, b4_legend], shadow=True, fontsize=12)\n",
    "fig.text(0.12, 0.9, 'Distributions through 1992 to 2018', fontsize=18, fontweight='bold')     \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A similar phenomenon is observed here. There are seasons that have a wide distribution or narrow distribution for Top 4 team. And the overall trend of goal and goal_against did not change throughout the years.\n",
    "\n",
    "As a result, Season did not affect the other features significantly but just some seasons there was a team that outperformed others by far so that it even makes a difference among Top 4 teams."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Club statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The data before season 2006 have many features that are zero due to the reason as follows:**  \n",
    "\"When the Premier League began in 1992/93, only a basic level of match data was gathered. Over time this has increased and since 2006/07 a wide range of statistics are now provided. The information below shows a breakdown of the statistics on the Premier League website and the season this data originated.\" **from EPL offical website, https://www.premierleague.com/stats/clarification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['aerial_battles', 'big_chance_created', 'clearance', 'cross', 'cross_accuracy', 'goal_conceded_per_match', \n",
    "            'goal_per_match', 'interceptions', 'pass_accuracy', 'pass_per_game', 'shooting_accuracy', 'shot_on_target', 'tackle_success']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(7, 2, figsize=(10,15))\n",
    "cols = features\n",
    "\n",
    "for i, col in enumerate(cols):\n",
    "    t4_index = top4[col].value_counts().index\n",
    "    t4_values = np.mean(top4[col])\n",
    "    b4_index = below4[col].value_counts().index\n",
    "    b4_values = np.mean(below4[col])\n",
    "\n",
    "    ax.flatten()[i].bar(x=0.5-0.075/2, height=t4_values, width=0.1, color=t4_color, edgecolor='black', linewidth=2)\n",
    "    ax.flatten()[i].bar(x=0.5+0.075/2, height=b4_values, width=0.1, color=b4_color, edgecolor='black', linewidth=2)\n",
    "\n",
    "    ax.flatten()[i].grid(which='major', axis='x', zorder=0, alpha=0.3)\n",
    "    ax.flatten()[i].grid(which='major', axis='y', zorder=0, alpha=0.3)\n",
    "\n",
    "    ax.flatten()[i].set_xticks(np.arange(0,2,1))\n",
    "    ax.flatten()[i].set_title(col.upper(), weight='bold', fontsize=20)\n",
    "    ax.flatten()[i].set_facecolor(b_color)\n",
    "\n",
    "    ax.flatten()[i].spines['top'].set_visible(False)\n",
    "    ax.flatten()[i].spines['right'].set_visible(False)\n",
    "    ax.flatten()[i].spines['bottom'].set_linewidth(4)\n",
    "    ax.flatten()[i].spines['left'].set_linewidth(4)\n",
    "\n",
    "ax.flatten()[-1].set_facecolor(b_color)\n",
    "ax.flatten()[-1].grid(which='major', axis='x', zorder=0, color=b_color)\n",
    "ax.flatten()[-1].grid(which='major', axis='y', zorder=0, color=b_color)\n",
    "ax.flatten()[-1].spines['top'].set_visible(False)\n",
    "ax.flatten()[-1].spines['right'].set_visible(False)\n",
    "ax.flatten()[-1].spines['bottom'].set_linewidth(False)\n",
    "ax.flatten()[-1].spines['left'].set_linewidth(False)\n",
    "ax.flatten()[-1].get_xaxis().set_visible(False)\n",
    "ax.flatten()[-1].get_yaxis().set_visible(False)\n",
    "\n",
    "fig.set_facecolor(b_color)\n",
    "fig.legend(bbox_to_anchor=(0.98, 0.15), handles=[t4_legend, b4_legend], shadow=True, fontsize=14)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let’s take a look at club statistics. \n",
    "\n",
    "For  Big change created, Top 4 obviously has a much higher value than Below 4. In contrast, Below 4 has a much higher Goal conceded per match value than Top 4. These two features may be too obvious, a higher value in Big chance created means a team has a higher chance scoring a goal and a higher value in Goal conceded per match literally means a team has a higher rate to get scored. \n",
    "\n",
    "Features that are not directly related to score show interesting insights. It looks like Aerial battles is not different between Top 4 and Below 4, which means that the number of Aerial battles does not influence the match enough to change the outcome of a match. For Clearance Top 4 has less value than Below 4. This could mean that Top 4 has fewer situations where they need to clear the ball in defensive situations; thus, more clearances could indicate that a team is less dominant than another team during the match. For Cross and Cross accuracy, they both have a similar level of accuracy in crossing, but Top 4 tends to have more crossing than Below 4, which means they are more aggressive in attacking situations.\n",
    "\n",
    "Goal per match shows that Top 4 has much higher value than Below 4 and the same insight goes with Shot on target, higher value in Shot on target means it has a better chance in scoring a goal. There is less difference in Shooting accuracy than Shot on target. Shooting accuracy means accuracy of shooting that are shots on goal (target). Therefore, this indicates that Below 4 tries less shootings or they have less attacking situations than Top 4. Similar relationships can be found in Pass per game and Pass accuracy. Top 4 has higher in both features and there is less difference in accuracy. Lastly, Interceptions and Tackle success do not affect an outcome of a match based on its plots. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Additional: Correlation among features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = re.compile('/\\d*')\n",
    "\n",
    "past_seasons['season'] = past_seasons['season'].apply(lambda x: pattern.sub('', x))\n",
    "\n",
    "past_seasons['season'] = past_seasons['season'].astype(int)\n",
    "\n",
    "p_season_corr = past_seasons.corr()\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "sns.heatmap(p_season_corr, \n",
    "            mask=np.zeros_like(p_season_corr, dtype=np.bool), \n",
    "            annot=True, cmap=sns.cubehelix_palette(as_cmap=True), square=True, linewidths=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Baseline model for \"tables\" and \"clubstats\" dataset. \n",
    "\n",
    "#### Baseline models with every feature\n",
    "Need to think about which models to use since there are not many data points.  \n",
    "\n",
    "\"\"\"  \n",
    "If the training data is sufficiently large and the number of observations is higher as compared to the number of features, one can go for low bias/high variance algorithms like KNN, Decision trees, or kernel SVM.  \n",
    "\n",
    "In general, small datasets require models that have low complexity (or high bias) to avoid overfitting the model to the data.  \n",
    "\n",
    "ref: https://www.kdnuggets.com/2020/05/guide-choose-right-machine-learning-algorithm.html  \n",
    "\"\"\"\n",
    "\n",
    "#### Choosing the high bias models  due to small dataset\n",
    "- Naive Bayes\n",
    "- Linear SVM\n",
    "- Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, y, X_valid, y_valid):\n",
    "    nb = naive_bayes.GaussianNB()\n",
    "    lsvm = LinearSVC(random_state=2021)\n",
    "    logit = LogisticRegression(random_state=2021)\n",
    "    \n",
    "    nb.fit(X, y)\n",
    "    lsvm.fit(X, y)\n",
    "    logit.fit(X, y)\n",
    "    \n",
    "    nb_preds = nb.predict(X_valid)\n",
    "    lsvm_preds = lsvm.predict(X_valid)\n",
    "    logit_preds = logit.predict(X_valid)\n",
    "    \n",
    "    print((f'F1 Scores \\n Naive Bayes: {f1_score(y_valid, nb_preds)} \\n' \n",
    "           f' Linear SVM: {f1_score(y_valid, lsvm_preds)} \\n' \n",
    "           f' Logitstic Regression: {f1_score(y_valid, logit_preds)}'))\n",
    "    \n",
    "    return [nb, lsvm, logit]\n",
    "\n",
    "\n",
    "def plot_learning(X, y):\n",
    "    nb = naive_bayes.GaussianNB()\n",
    "    lsvm = LinearSVC(random_state=2021)\n",
    "    logit = LogisticRegression(random_state=2021)\n",
    "    \n",
    "    models = [nb, lsvm, logit]\n",
    "    \n",
    "    fig, ax = plt.subplots(1,3, figsize=(20,5))\n",
    "    \n",
    "    for i in range(3):\n",
    "        train_sizes, train_score, valid_scores = learning_curve(models[i], X, y, cv=5)\n",
    "        ax.flatten()[i].plot(train_sizes, np.mean(train_score, axis=1), 'o-', color=b4_color, label='Training')\n",
    "        ax.flatten()[i].plot(train_sizes, np.mean(valid_scores, axis=1), 'o-', color=t4_color, label='CV')\n",
    "        ax.flatten()[i].legend()\n",
    "        ax.flatten()[i].set_title(f'{models[i]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating two models for tables and club statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_cols = list(tables.columns)\n",
    "t_cols.append('is_top4')\n",
    "\n",
    "c_cols = list(clubstats.columns)\n",
    "c_cols.append('is_top4')\n",
    "\n",
    "tables_train = data[t_cols]\n",
    "clubstats_train = data[c_cols]\n",
    "tables_train = tables_train.drop('club_name', axis=1)\n",
    "clubstats_train = clubstats_train.drop('club_name', axis=1)\n",
    "\n",
    "\n",
    "pattern = re.compile('/\\d*')\n",
    "\n",
    "tables_train['season'] = tables_train['season'].apply(lambda x: pattern.sub('', x))\n",
    "clubstats_train['season'] = clubstats_train['season'].apply(lambda x: pattern.sub('', x))\n",
    "\n",
    "tables_train['season'] = tables_train['season'].astype(int)\n",
    "clubstats_train['season'] = clubstats_train['season'].astype(int)\n",
    "\n",
    "tables_test = tables_train[tables_train['season'] == 2019]\n",
    "clubstats_test = clubstats_train[clubstats_train['season'] == 2019]\n",
    "\n",
    "num_match = tables_test[['won', 'drawn', 'lost']].apply(np.sum, axis=1)\n",
    "\n",
    "for i, n in enumerate(num_match):\n",
    "    tables_test.loc[i,['drawn', 'goal', 'goal_against', 'lost', 'points', 'won']] /= n\n",
    "\n",
    "    \n",
    "tables_train = tables_train.drop(tables_test.index, axis=0)\n",
    "clubstats_train = clubstats_train.drop(clubstats_test.index, axis=0)\n",
    "\n",
    "tables_train.loc[:, ['drawn', 'goal', 'goal_against', 'lost', 'points', 'won']] /= 38\n",
    "\n",
    "# Shuffle the dataset\n",
    "tables_train = tables_train.sample(frac=1, random_state=2021)\n",
    "clubstats_train = clubstats_train.sample(frac=1, random_state=2021)\n",
    "\n",
    "\n",
    "# Selected the periods that have non zero data for club statistics, which is from 2006/07 to 2019/20\n",
    "clubstats_train = clubstats_train[clubstats_train['season'] > 2005]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create train, cv, and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Train and Test set\n",
    "X_club_train, X_club_test, y_club_train, y_club_test = train_test_split(clubstats_train.drop('is_top4', axis=1), \n",
    "                                                                        clubstats_train['is_top4'], \n",
    "                                                                        test_size=0.4, \n",
    "                                                                        random_state=2021, \n",
    "                                                                        stratify=clubstats_train['is_top4'])\n",
    "\n",
    "X_table_train, X_table_test, y_table_train, y_table_test = train_test_split(tables_train.drop('is_top4', axis=1), \n",
    "                                                                            tables_train['is_top4'], \n",
    "                                                                            test_size=0.4, \n",
    "                                                                            random_state=2021, \n",
    "                                                                            stratify=tables_train['is_top4'])\n",
    "\n",
    "# Split Test set for validation set\n",
    "X_club_valid, X_club_test, y_club_valid, y_club_test = train_test_split(X_club_test, \n",
    "                                                                        y_club_test, \n",
    "                                                                        test_size=0.5, \n",
    "                                                                        random_state=2021, \n",
    "                                                                        stratify=y_club_test)\n",
    "\n",
    "X_table_valid, X_table_test, y_table_valid, y_table_test = train_test_split(X_table_test, \n",
    "                                                                            y_table_test, \n",
    "                                                                            test_size=0.5, \n",
    "                                                                            random_state=2021, \n",
    "                                                                            stratify=y_table_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For tables_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_nb, t_lsvm, t_logit = train(X_table_train, y_table_train, X_table_valid, y_table_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_learning(X_table_train, y_table_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every model overfits a lot except Naive Bayes. This may due to small data points and not many features in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For clubstats_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_nb, c_lsvm, c_logit = train(X_club_train, y_club_train, X_club_valid, y_club_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning(X_club_train, y_club_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For tables_train & clubstats_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables_clubs = pd.concat([tables_train.drop('is_top4',axis=1), clubstats_train.drop('season', axis=1)], axis=1)\n",
    "tables_clubs = tables_clubs.drop(tables_clubs[tables_clubs['season'] < 2006].index, axis=0)\n",
    "\n",
    "# Split Train and Test set\n",
    "X_tc_train, X_tc_test, y_tc_train, y_tc_test = train_test_split(tables_clubs.drop('is_top4', axis=1), \n",
    "                                                                tables_clubs['is_top4'], \n",
    "                                                                test_size=0.4, \n",
    "                                                                random_state=2021, \n",
    "                                                                stratify=tables_clubs['is_top4'])\n",
    "\n",
    "# Split Test set for validation set\n",
    "X_tc_valid, X_tc_test, y_tc_valid, y_tc_test = train_test_split(X_tc_test, \n",
    "                                                                y_tc_test, \n",
    "                                                                test_size=0.5, \n",
    "                                                                random_state=2021, \n",
    "                                                                stratify=y_tc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tc_nb, tc_lsvm, tc_logit = train(X_tc_train, y_tc_train, X_tc_valid, y_tc_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning(X_tc_train, y_tc_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy was not in percentage.\n",
    "acc_cols = []\n",
    "\n",
    "for col in clubstats.columns:\n",
    "    if 'accuracy' in col:\n",
    "        acc_cols.append(col)\n",
    "        \n",
    "clubstats_train[acc_cols] = clubstats_train[acc_cols] * 0.01\n",
    "\n",
    "# Drop features that are not siginificantly different between two groups\n",
    "drop_feat = ['aerial_battles', 'clearance', 'interceptions']\n",
    "fe_tables = tables_train.drop(['position', 'drawn'], axis=1)\n",
    "clubstats_train = clubstats_train.drop(drop_feat, axis=1)\n",
    "\n",
    "#Create Tables + Clubstats dataset\n",
    "tables_clubs = pd.concat([fe_tables.drop('is_top4',axis=1), clubstats_train.drop('season', axis=1)], axis=1)\n",
    "tables_clubs = tables_clubs.drop(tables_clubs[tables_clubs['season'] < 2006].index, axis=0)\n",
    "\n",
    "# Split Train and Test set\n",
    "X_club_train, X_club_test, y_club_train, y_club_test = train_test_split(clubstats_train.drop('is_top4', axis=1), \n",
    "                                                                        clubstats_train['is_top4'], \n",
    "                                                                        test_size=0.4, \n",
    "                                                                        random_state=2021, \n",
    "                                                                        stratify=clubstats_train['is_top4'])\n",
    "\n",
    "X_tc_train, X_tc_test, y_tc_train, y_tc_test = train_test_split(tables_clubs.drop('is_top4', axis=1), \n",
    "                                                                tables_clubs['is_top4'], \n",
    "                                                                test_size=0.4, \n",
    "                                                                random_state=2021, \n",
    "                                                                stratify=tables_clubs['is_top4'])\n",
    "\n",
    "# Split Test set for validation set\n",
    "X_club_valid, X_club_test, y_club_valid, y_club_test = train_test_split(X_club_test, \n",
    "                                                                        y_club_test, \n",
    "                                                                        test_size=0.5, \n",
    "                                                                        random_state=2021, \n",
    "                                                                        stratify=y_club_test)\n",
    "\n",
    "X_tc_valid, X_tc_test, y_tc_valid, y_tc_test = train_test_split(X_tc_test, \n",
    "                                                                y_tc_test, \n",
    "                                                                test_size=0.5, \n",
    "                                                                random_state=2021, \n",
    "                                                                stratify=y_tc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_nb, c_lsvm, c_logit = train(X_club_train, y_club_train, X_club_valid, y_club_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning(X_club_train, y_club_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tc_nb, tc_lsvm, tc_logit = train(X_tc_train, y_tc_train, X_tc_valid, y_tc_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_learning(X_tc_train, y_tc_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real result from the offcial website: https://www.premierleague.com/tables?co=1&se=274&ha=-1\n",
    "true_position = [1, 2, 5, 4, 3, 7, 9, 6, 8, 10, 14, 12, 13, 11, 15, 16, 19, 18, 17, 20]\n",
    "y_test = [1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_X = tables_test.drop(['is_top4', 'position', 'drawn'], axis=1)\n",
    "club_X = clubstats_test.drop('is_top4', axis=1)\n",
    "\n",
    "club_X[acc_cols] = club_X[acc_cols] * .01\n",
    "club_X = club_X.drop(drop_feat, axis=1)\n",
    "table_X = pd.concat([table_X, club_X.drop('season', axis=1)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print((f'F1 Score \\n'\n",
    "      f'tc_nb: {f1_score(y_test, tc_nb.predict(table_X))} \\n'\n",
    "      f'tc_logit: {f1_score(y_test, tc_logit.predict(table_X))} \\n'\n",
    "      f'c_nb: {f1_score(y_test, c_nb.predict(club_X))} \\n'\n",
    "      f'c_logit: {f1_score(y_test, c_logit.predict(club_X))}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropthe lowest two models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ave_preds = (tc_logit.predict_proba(table_X)[:, 1] + c_nb.predict_proba(club_X)[:, 1]) / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Prediction table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_table = current_season[['club_name', 'position']]\n",
    "\n",
    "pd.concat([final_table, pd.Series(true_position, name='final_position'),\n",
    "           pd.Series(ave_preds, name='ensemble_result'),\n",
    "           pd.Series(y_test, name='is_top4')], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thoughts on prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are nine games or ten games for some teams left to finish the 2019/20 season, which means that any team can get 27 or 30 points by winning the rest of the games. Therefore, there could be a lot of changes in the current standing. With many uncertainties, models was able to predicted descent result. One of the interesting observations is that the model generally give a higher percentage to the teams that are known for better teams than other(?) even though, they are in the lower position in the table. This shows that there are other key features that affects the result of the game.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limitations and others"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Dataset does not include other features that might be important for performance of a team such as Team mentality, number of players who are injured, whether a team has world class players or not, etc… Therefore, there might be other important features that have a positive or negativerelationship with getting into the top 4. \n",
    "2. Dataset is pretty small"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
